version: '3.8'

services:
  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    environment:
      - NODE_ENV=development
      - PORT=5000
      - OLLAMA_URL=http://ollama:11434
      - VOICE_AGENT_URL=http://voice-agent:5001
    volumes:
      - ./backend:/app
      - ./data:/app/data
      - /app/node_modules
    depends_on:
      - ollama
      - voice-agent
    networks:
      - interview-network

  # Voice Agent (Python)
  voice-agent:
    build:
      context: ./voice-agent
      dockerfile: Dockerfile
    ports:
      - "5001:5001"
    environment:
      - FLASK_ENV=development
      - PORT=5001
    volumes:
      - ./voice-agent:/app
      - ./data/audio:/app/audio
    networks:
      - interview-network

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://localhost:5000
      - VITE_WS_URL=ws://localhost:5000
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - backend
    networks:
      - interview-network

  # Ollama for LLM
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - interview-network
    command: serve

networks:
  interview-network:
    driver: bridge

volumes:
  ollama-data:
