# ğŸ¤ Interview Practice Partner ğŸš€  
An interactive AI-powered interview coach that helps you **practice, improve, and ace** your job interviews â€” complete with realistic conversations, probing follow-ups, and actionable feedback.

---

## ğŸŒŸ Overview  
- **ğŸ¯ Purpose:** Help job-seekers prepare confidently with **role-specific mock interviews**, natural follow-ups, and structured evaluations.  
- **ğŸ™ï¸ Interaction style:** Voice-first (STT/TTS) with chat as a convenient fallback.  
- **ğŸ‘¥ Ideal for:** Software engineers, sales reps, retail staff, customer support candidates, and anyone preparing for interviews.

---

## âœ¨ Features

- **ğŸ§‘â€ğŸ’¼ Role-specific mock interviews**  
  Tailored sessions based on your target job (Software Engineer, Sales Rep, Retail Associate, etc.).

- **ğŸ¤” Realistic follow-ups**  
  Smart, context-aware probes â€” just like real interviewers asking *â€œCan you clarify?â€* or *â€œWalk me through your reasoning.â€*

- **ğŸ“ Post-interview evaluation**  
  Get structured feedback on communication, technical depth, clarity, problem-solving, and more.

- **ğŸ“Š Scoring & Practical Tips**  
  Receive a concise score, rubric, and targeted tips to improve your next attempt.

- **ğŸ¤ Voice + ğŸ’¬ Chat**  
  Primary interaction via voice, with text chat available for quiet environments.

- **ğŸª¶ Lightweight frontend + backend**  
  Simple browser UI (`frontend/`) and a FastAPI backend (`backend/`) for orchestration and evaluation logic.

---

## ğŸ§  Why Choose Mistral with Ollama?

- **ğŸ“˜ Excellent instruction-following**  
  Mistral 7B models are reliable for generating interview questions, probing answers, and performing evaluations.

- **âš–ï¸ Balanced size vs power**  
  Strong capability without the heavy compute requirements of huge models.

- **ğŸ’» Easy self-hosting via Ollama**  
  Fast local inference, privacy-friendly, and smooth model management â€” especially with quantized GGUF builds.

---

## ğŸ†“ Open-Source Models You Can Use

A few solid LLMs for self-hosted interview agents:

- **ğŸŒ€ Mistral 7B** â€” Highly capable & efficient.  
- **ğŸ‘ LLaMA 2 / 3** â€” Large ecosystem, varied model sizes.  
- **ğŸ’ Gemma** â€” Lightweight, fast, and inference-friendly.  
- **ğŸ¦… Falcon (7B / 40B / 180B)** â€” Great reasoning in larger versions.  
- **ğŸŒ BLOOM** â€” Multilingual & versatile.

> ğŸ’¡ *Tip:* For local setups, prefer smaller or quantized variants (4-bit/8-bit/GGUF) unless you have a powerful GPU.

---

## âš™ï¸ Quick Ollama Commands (PowerShell)

Pull a model:  
```pwsh
ollama pull mistral
```

List installed models:  
```pwsh
ollama list
```

Run a model:  
```pwsh
ollama run mistral
```

---

## ğŸ—ï¸ System Architecture

### ğŸ–¥ï¸ Frontend (`frontend/`)  
Handles UI, microphone access, audio playback, and sending inputs to the backend.

### ğŸ§© Backend (`backend/`)  
FastAPI server containing:  
- Session management  
- Templates & prompt logic  
- LLM communication  
- Evaluation / scoring pipeline

### ğŸ¤– LLM API  
Self-hosted (Ollama) or cloud-based large language models generate:  
- Questions  
- Follow-ups  
- Evaluations & feedback

### ğŸ”Š STT / TTS (optional)  
- Browser Web Speech API for demos  
- Cloud STT/TTS (Google, Azure, AWS) or open-source Coqui for production use

---

## ğŸ” Flow Diagram (Simplified)

**User voice/chat â†’ Frontend â†’ Backend â†’ LLM â†’ Backend scoring â†’ Frontend output/TTS**

ğŸ§ Speak â†’ ğŸ§  Think â†’ ğŸ—£ï¸ Respond â†’ ğŸ“Š Evaluate â†’ ğŸ” Improve
