# ğŸ¤ Interview Practice Partner ğŸš€  
An interactive AI-powered interview coach that helps you **practice, improve, and ace** your job interviews â€” complete with realistic conversations, probing follow-ups, and actionable feedback.

---

## ğŸŒŸ Overview  
- **ğŸ¯ Purpose:** Help job-seekers prepare confidently with **role-specific mock interviews**, natural follow-ups, and structured evaluations.  
- **ğŸ™ï¸ Interaction style:** Voice-first (STT/TTS) with chat as a convenient fallback.  
- **ğŸ‘¥ Ideal for:** Software engineers, sales reps, retail staff, customer support candidates, and anyone preparing for interviews.

---

## âš™ï¸ Installation & Running the Project

### ğŸ§© 1. Clone the repository
```bash
git clone <your-repo-url>
cd interview-practice-partner
```

---

### ğŸ–¥ï¸ 2. Run the Backend (FastAPI)

#### ğŸ Requirements
- Python 3.9+
- FastAPI
- uvicorn (optional, but recommended)

#### â–¶ï¸ Start backend
You can run the backend directly:

```bash
python main.py
```

OR using uvicorn:

```bash
uvicorn main:app --reload --port 8000
```

Backend will run at:
```
http://localhost:8000
```

---

### ğŸŒ 3. Run the Frontend

The frontend is completely static â€” no build needed.

To start:

1. Open the `frontend/` directory  
2. Double-click `index.html` **OR** open it with any browser

That's it! ğŸ‰  
Your frontend will communicate with the backend at `http://localhost:8000`.

---

## âœ¨ Features

- **ğŸ§‘â€ğŸ’¼ Role-specific mock interviews**  
- **ğŸ¤” Realistic follow-ups**  
- **ğŸ“ Post-interview evaluation**  
- **ğŸ“Š Scores & actionable tips**  
- **ğŸ¤ Voice + ğŸ’¬ Chat modes**  
- **ğŸª¶ Lightweight frontend + backend**

---

## ğŸ§  Why Choose Mistral with Ollama?

- ğŸ“˜ Excellent instruction-following  
- âš–ï¸ Great balance of size & capability  
- ğŸ’» Easy local hosting with Ollama (fast, private, efficient)

---

## ğŸ†“ Open-Source Models You Can Use

- ğŸŒ€ Mistral 7B  
- ğŸ‘ LLaMA 2 / 3  
- ğŸ’ Gemma  
- ğŸ¦… Falcon  
- ğŸŒ BLOOM  

> ğŸ’¡ Use small or quantized builds for local inference.

---

## âš™ï¸ Quick Ollama Commands (PowerShell)

```pwsh
ollama pull mistral
ollama list
ollama run mistral
```

---

## ğŸ—ï¸ System Architecture

### ğŸ–¥ï¸ Frontend (`frontend/`)
- Handles UI  
- Microphone access (voice input)  
- Audio playback  
- Requests â†’ backend  

### ğŸ§© Backend (`backend/`)
- FastAPI app  
- Prompt orchestration  
- LLM calls  
- Evaluation logic  

### ğŸ¤– LLM API
- Self-hosted (Ollama) or cloud LLM  
- Generates questions, follow-ups & feedback  

### ğŸ”Š STT/TTS (optional)
- Browser Web Speech API  
- Or cloud/open-source alternatives  

---

## ğŸ” Flow Diagram (Simplified)

**User** â†’ **Frontend** â†’ **Backend** â†’ **LLM** â†’ **Backend scoring** â†’ **Frontend Output/TTS**

ğŸ§ Speak â†’ ğŸ§  Think â†’ ğŸ—£ï¸ Respond â†’ ğŸ“Š Evaluate â†’ ğŸ” Improve